import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim.lr_scheduler import ReduceLROnPlateau
import numpy as np
from torch.autograd import grad
import matplotlib.pyplot as plt
import os

Re = 1
nu = 1.0 / Re  
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
pi = torch.tensor(np.pi, device=device, dtype=torch.float32)

x_range = (0.0, pi.item())
y_range = (0.0, pi.item())
t_range = (0.0, 1.0)

N_e = 6400 
N_i = 1600  
N_b = 1600  

num_iterations = 15001 
lr = 0.001             
alpha = 0.5    
beta = 0.5         
hidden_layers = 6        
hidden_dim = 128      
torch.manual_seed(42)
np.random.seed(42)

class PINN(nn.Module):
    def __init__(self):
        super(PINN, self).__init__()
        self.input_layer = nn.Linear(3, hidden_dim)
        self.hidden = nn.Sequential(
            *[nn.Sequential(nn.Linear(hidden_dim, hidden_dim), nn.SiLU()) 
              for _ in range(hidden_layers)]
        )
        self.output_layer = nn.Linear(hidden_dim, 3)

    def forward(self, x, y, t):
        inputs = torch.cat([x, y, t], dim=1)
        x = self.input_layer(inputs)
        x = self.hidden(x)
        u1, u2, P = self.output_layer(x).chunk(3, dim=1)
        return u1, u2, P

def sample_interior_points():
    n = int(np.sqrt(N_e))  
    x = torch.linspace(x_range[0], x_range[1], n, device=device)
    y = torch.linspace(y_range[0], y_range[1], n, device=device)
    x_grid, y_grid = torch.meshgrid(x, y, indexing="ij")
    
    x_flat = x_grid.reshape(-1, 1)
    y_flat = y_grid.reshape(-1, 1)
    
    t_flat = torch.rand(n*n, 1, device=device) * (t_range[1]-t_range[0]) + t_range[0]
    
    
    return x_flat.requires_grad_(True), y_flat.requires_grad_(True), t_flat.requires_grad_(True)

def sample_initial_points():
    n = int(np.sqrt(N_i))
    x = torch.linspace(x_range[0], x_range[1], n, device=device)
    y = torch.linspace(y_range[0], y_range[1], n, device=device)
    x_grid, y_grid = torch.meshgrid(x, y, indexing="ij")
    
    x_flat = x_grid.reshape(-1, 1)
    y_flat = y_grid.reshape(-1, 1)
    t_flat = torch.zeros(n*n, 1, device=device)  

    
    return x_flat.requires_grad_(True), y_flat.requires_grad_(True), t_flat.requires_grad_(True)

def sample_boundary_points():
    n_per_side = N_b // 4
    
    x1 = torch.zeros(n_per_side, 1, device=device)
    y1 = torch.linspace(y_range[0], y_range[1], n_per_side, device=device).reshape(-1, 1)
    t1 = torch.rand(n_per_side, 1, device=device)
    
    x2 = pi*torch.ones(n_per_side, 1, device=device)
    y2 = torch.linspace(y_range[0], y_range[1], n_per_side, device=device).reshape(-1, 1)
    t2 = torch.rand(n_per_side, 1, device=device)
    
    x3 = torch.linspace(x_range[0], x_range[1], n_per_side, device=device).reshape(-1, 1)
    y3 = torch.zeros(n_per_side, 1, device=device)
    t3 = torch.rand(n_per_side, 1, device=device)
    
    x4 = torch.linspace(x_range[0], x_range[1], n_per_side, device=device).reshape(-1, 1)
    y4 = pi*torch.ones(n_per_side, 1, device=device)
    t4 = torch.rand(n_per_side, 1, device=device)
    
    x = torch.cat([x1, x2, x3, x4], dim=0)
    y = torch.cat([y1, y2, y3, y4], dim=0)
    t = torch.cat([t1, t2, t3, t4], dim=0)
    
    
    return x.requires_grad_(True), y.requires_grad_(True), t.requires_grad_(True)

def get_analytical_solution(x, y, t):
    exp_term = torch.exp(-2 * t)
    exp_term1 = torch.exp(-4 * t)
    u1_star = torch.sin(x)*torch.sin(y) * exp_term
    u2_star = torch.cos(x)*torch.cos(y)  *  exp_term
    P_star = (1/4) * (torch.cos(2*x)-torch.cos(2*y)) *exp_term1
    return u1_star, u2_star, P_star

def compute_ns_residuals(u1, u2, P, x, y, t):
    u1_x = grad(u1.sum(), x, create_graph=True)[0]
    u1_y = grad(u1.sum(), y, create_graph=True)[0]
    u1_t = grad(u1.sum(), t, create_graph=True)[0]
    
    u2_x = grad(u2.sum(), x, create_graph=True)[0]
    u2_y = grad(u2.sum(), y, create_graph=True)[0]
    u2_t = grad(u2.sum(), t, create_graph=True)[0]
    
    P_x = grad(P.sum(), x, create_graph=True)[0]
    P_y = grad(P.sum(), y, create_graph=True)[0]
    
    u1_xx = grad(u1_x.sum(), x, create_graph=True)[0]
    u1_yy = grad(u1_y.sum(), y, create_graph=True)[0]
    
    u2_xx = grad(u2_x.sum(), x, create_graph=True)[0]
    u2_yy = grad(u2_y.sum(), y, create_graph=True)[0]
    
    res_x = u1_t + u1*u1_x + u2*u1_y + P_x - nu*(u1_xx + u1_yy)
    res_y = u2_t + u1*u2_x + u2*u2_y + P_y - nu*(u2_xx + u2_yy)
    res_div = u1_x + u2_y  
    
    return res_x, res_y, res_div


def compute_total_loss(model):
    x_e, y_e, t_e = sample_interior_points()
    u1_e, u2_e, P_e = model(x_e, y_e, t_e)
    res_x, res_y, res_div = compute_ns_residuals(u1_e, u2_e, P_e, x_e, y_e, t_e)
    loss_eq = (res_x**2).mean() + (res_y**2).mean() + (res_div**2).mean()
    
    x_i, y_i, t_i = sample_initial_points()
    u1_i, u2_i, P_i = model(x_i, y_i, t_i)
    u1_i_star, u2_i_star, P_i_star = get_analytical_solution(x_i, y_i, t_i)
    loss_init_u = ((u1_i - u1_i_star)**2).mean() + ((u2_i - u2_i_star)** 2).mean()
    loss_init_p = ((P_i - P_i_star)**2).mean()
    loss_init = loss_init_u + loss_init_p
    
    x_b, y_b, t_b = sample_boundary_points()
    u1_b, u2_b, P_b = model(x_b, y_b, t_b)
    u1_b_star, u2_b_star, P_b_star = get_analytical_solution(x_b, y_b, t_b)
    loss_bnd_u = ((u1_b - u1_b_star)**2).mean() + ((u2_b - u2_b_star)** 2).mean()
    loss_bnd_p = ((P_b - P_b_star)**2).mean()
    loss_bnd = loss_bnd_u  +  loss_bnd_p
    loss_bnd /= 4  
    
    total_loss = loss_eq + alpha * loss_init + beta * loss_bnd
    return total_loss, loss_eq, loss_init, loss_bnd


def visualize_results(model, loss_history=None, t_val=0.5, save_path=None, show_plot=False):
    model.eval()
    with torch.no_grad():
        n_grid = 100  
        x_val = torch.linspace(x_range[0], x_range[1], n_grid, device=device).unsqueeze(1)
        y_val = torch.linspace(y_range[0], y_range[1], n_grid, device=device).unsqueeze(1)
        t_val = torch.tensor([t_val], device=device).unsqueeze(1) 
        
        x_grid, y_grid, t_grid = torch.meshgrid(
            x_val.squeeze(), y_val.squeeze(), t_val.squeeze(), indexing="ij"
        )
        x_flat = x_grid.unsqueeze(-1).reshape(-1, 1)
        y_flat = y_grid.unsqueeze(-1).reshape(-1, 1)
        t_flat = t_grid.unsqueeze(-1).reshape(-1, 1)
        
        u1_pred, u2_pred, P_pred = model(x_flat, y_flat, t_flat)
        u1_star, u2_star, P_star = get_analytical_solution(x_flat, y_flat, t_flat)
        
        u1_pred_grid = u1_pred.reshape(n_grid, n_grid).cpu().numpy()
        u1_star_grid = u1_star.reshape(n_grid, n_grid).cpu().numpy()
        u1_err_grid = np.abs(u1_pred_grid - u1_star_grid)
        
        u2_pred_grid = u2_pred.reshape(n_grid, n_grid).cpu().numpy()
        u2_star_grid = u2_star.reshape(n_grid, n_grid).cpu().numpy()
        u2_err_grid = np.abs(u2_pred_grid - u2_star_grid)
        
        P_pred_grid = P_pred.reshape(n_grid, n_grid).cpu().numpy()
        P_star_grid = P_star.reshape(n_grid, n_grid).cpu().numpy()
        P_err_grid = np.abs(P_pred_grid - P_star_grid)
        
        x_plot = x_grid.cpu().numpy()[:, :, 0]
        y_plot = y_grid.cpu().numpy()[:, :, 0]
        
        fig, axes = plt.subplots(2, 3, figsize=(16, 12))

        plt.subplots_adjust(
            wspace=0.1, 
            hspace=0.3,   
            top=0.9,     
            bottom=0.3,  
            left=0.1,   
            right=0.9   
        )
        if save_path:
            iter_num = save_path.split("_")[-1].split(".")[0]
            fig.suptitle(f'(Case 2) PINNs Results at t={t_val.item()}  | Iteration {iter_num}', 
                         fontsize=16, y=0.98)
        else:
            fig.suptitle(f'(Case 2) PINNs Results at t={t_val.item()} ', 
                         fontsize=16, y=0.98)
        
        cmap_pred = 'viridis'
        cmap_err = 'viridis' 


        im1 = axes[0, 0].contourf(x_plot, y_plot, u1_pred_grid, cmap=cmap_pred, levels=50)
        axes[0, 0].set_title('(a) u₁ (PINN Prediction)', fontsize=12)
        axes[0, 0].set_xlabel('x')
        axes[0, 0].set_ylabel('y')
        axes[0, 0].set_aspect('equal')
        plt.colorbar(im1, ax=axes[0, 0], shrink=0.6)
        
        im2 = axes[0, 1].contourf(x_plot, y_plot, u1_star_grid, cmap=cmap_pred, levels=50)
        axes[0, 1].set_title('(c) u₁ (Analytical Solution)', fontsize=12)
        axes[0, 1].set_aspect('equal')
        plt.colorbar(im2, ax=axes[0, 1], shrink=0.6)
        
        im3 = axes[0, 2].contourf(x_plot, y_plot, u1_err_grid, cmap=cmap_err, levels=50)
        axes[0, 2].set_title(f'(e) u₁ Absolute Error (max={u1_err_grid.max():.4f})', fontsize=12)
        axes[0, 2].set_aspect('equal')
        plt.colorbar(im3, ax=axes[0, 2], shrink=0.6)
        
  
        im4 = axes[1, 0].contourf(x_plot, y_plot, u2_pred_grid, cmap=cmap_pred, levels=50)
        axes[1, 0].set_title('(b) u₂ (PINN Prediction)', fontsize=12)
        axes[1, 0].set_aspect('equal')
        plt.colorbar(im4, ax=axes[1, 0], shrink=0.6)
        
        im5 = axes[1, 1].contourf(x_plot, y_plot, u2_star_grid, cmap=cmap_pred, levels=50)
        axes[1, 1].set_title('(d) u₂ (Analytical Solution)', fontsize=12)
        axes[1, 1].set_aspect('equal')
        plt.colorbar(im5, ax=axes[1, 1], shrink=0.6)
        
        im6 = axes[1, 2].contourf(x_plot, y_plot, u2_err_grid, cmap=cmap_err, levels=50)
        axes[1, 2].set_title(f'(f) u₂ Absolute Error (max={u2_err_grid.max():.4f})', fontsize=12)
        axes[1, 2].set_aspect('equal')
        plt.colorbar(im6, ax=axes[1, 2], shrink=0.6)
 
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        
        if show_plot:
            plt.show()
        else:
            plt.close(fig)


def train_pinn():
    os.makedirs("pinn_results", exist_ok=True)
    
    model = PINN().to(device)
    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-6)
    scheduler = ReduceLROnPlateau(
        optimizer,
        mode='min',
        factor=0.5,
        patience=1000, 
        min_lr=1e-7
    )
    loss_history = []

    model.train()
    for iter in range(num_iterations + 1):
        if iter == 10001 and not isinstance(optimizer, optim.LBFGS): 
            print("切换为LBFGS优化器...")
            optimizer = optim.LBFGS(model.parameters(), lr=0.1, max_iter=50, tolerance_grad=1e-7)
        
        def closure():
            optimizer.zero_grad()
            total_loss, loss_eq, loss_init, loss_bnd = compute_total_loss(model)
            total_loss.backward()
            return total_loss
        
        optimizer.step(closure)
        
        total_loss, loss_eq, loss_init, loss_bnd = compute_total_loss(model)
        scheduler.step(total_loss)

        if iter % 1000 == 0:
            loss_history.append({
                "iter": iter,
                "total_loss": total_loss.item(),
                "loss_eq": loss_eq.item(),
                "loss_init": loss_init.item(),
                "loss_bnd": loss_bnd.item()
            })
            print(f"迭代 {iter:5d} | 总损失: {total_loss.item():.6f} | "
                  f"方程残差: {loss_eq.item():.6f} | 初始损失: {loss_init.item():.6f} | "
                  f"边界损失: {loss_bnd.item():.6f}")
            
            save_path = f"pinn_results/results_iter_{iter}.png"
            visualize_results(model, loss_history=loss_history, t_val=0.5, save_path=save_path, show_plot=False)

    model.eval()
    with torch.no_grad():
        x_val = torch.linspace(x_range[0], x_range[1], 100, device=device).unsqueeze(1)
        y_val = torch.linspace(y_range[0], y_range[1], 100, device=device).unsqueeze(1)
        t_val = torch.tensor([0.5], device=device).unsqueeze(1)
        
        x_grid, y_grid, t_grid = torch.meshgrid(x_val.squeeze(), y_val.squeeze(), t_val.squeeze(), indexing="ij")
        x_flat = x_grid.unsqueeze(-1).reshape(-1, 1)
        y_flat = y_grid.unsqueeze(-1).reshape(-1, 1)
        t_flat = t_grid.unsqueeze(-1).reshape(-1, 1)
        
        u1_pred, u2_pred, P_pred = model(x_flat, y_flat, t_flat)
        u1_star, u2_star, P_star = get_analytical_solution(x_flat, y_flat, t_flat)
        
        l2_u1 = torch.sqrt(((u1_pred - u1_star)**2).mean())
        l2_u2 = torch.sqrt(((u2_pred - u2_star)** 2).mean())
        
        print("\n=== 验证结果（t=0.5）===")
        print(f"u1的L2误差: {l2_u1.item():.6f}")
        print(f"u2的L2误差: {l2_u2.item():.6f}")
    visualize_results(model, loss_history=loss_history, t_val=0.5, show_plot=True)
    
    return model, loss_history


if __name__ == "__main__":

    trained_model, loss_history = train_pinn()
    iter_list = [h["iter"] for h in loss_history]
    total_loss_list = [h["total_loss"] for h in loss_history]
    plt.figure(figsize=(10, 6))
    plt.semilogy(iter_list, total_loss_list, label="Total Loss", color="#1f77b4")
    plt.xlabel("Iteration", fontsize=12)
    plt.ylabel("Loss (Log Scale)", fontsize=12)
    plt.title("(Case2) PINNs Training Loss History (Unsteady Flow)", fontsize=14)
    plt.legend(fontsize=10)
    plt.grid(True, alpha=0.3)
    plt.show()
